{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR-md52MPsoM",
        "outputId": "f16aa806-2d9b-4d7c-ec54-eacd8b820add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "## using libraries tensorflow in keras\n",
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UdS_ii5PuYu",
        "outputId": "e78b6cff-5edb-4f2f-c388-526248dc63f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## tensorflow > 2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "E0axyDBvPupB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fu9PuYeu0XGD"
      },
      "outputs": [],
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWucAhlVPut1",
        "outputId": "d3966aae-88b9-4fb4-fc67-5d415d013998"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## initialise vocab size\n",
        "voc_size=10000"
      ],
      "metadata": {
        "id": "rjET7ua8PuwS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to convert to OHE representation- it fetches the index of words ( from sent ) lying at index in vocabulary\n",
        "\n",
        "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G13IbQV2Puy-",
        "outputId": "fc23711d-093a-4be8-853c-c3ad9f1e7379"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6060, 908, 5247, 3547], [6060, 908, 5247, 8495], [6060, 8174, 5247, 2302], [1562, 6014, 5082, 4334, 5278], [1562, 6014, 5082, 4334, 4845], [7071, 6060, 3252, 5247, 9815], [2158, 1094, 6864, 4334]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## word embedding representation"
      ],
      "metadata": {
        "id": "TAytcYWbPu1X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wpqPm0tb0XGF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "TZ8ZGUMAT5d1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## since length of above sentences vary, in order to train the model , we need to have them in same size so for padding we assume the sent length as 8, pad_swequence will make all sent of length 8 using 0,0,0s\n",
        "## so now input size is fixed\n",
        "## for post padding - 0s are added in end\n",
        "## if we take higher sent length = out of vocab issue can be avoided ; semantic meaning can be restored\n",
        "\n",
        "## pre padding\n",
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao8pGyU-T5iU",
        "outputId": "7f59e355-2ecb-46cd-d05e-9dadfa9f262b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 6060  908 5247 3547]\n",
            " [   0    0    0    0 6060  908 5247 8495]\n",
            " [   0    0    0    0 6060 8174 5247 2302]\n",
            " [   0    0    0 1562 6014 5082 4334 5278]\n",
            " [   0    0    0 1562 6014 5082 4334 4845]\n",
            " [   0    0    0 7071 6060 3252 5247 9815]\n",
            " [   0    0    0    0 2158 1094 6864 4334]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 10 feature dimesnions- everuy word is represented by 10 features, if we have huge data set; we use dim=500\n",
        "dim=10"
      ],
      "metadata": {
        "id": "rBht_pMjT5po"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## we will make a sequential model, after that we will below params to enbedding layer - voc_size; feature size, sent lengths\n",
        "##\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "id": "8Ff_sZ7tT5tC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzBJXhrBVAyv",
        "outputId": "58389a58-5342-4f8e-ee1e-acd80d082082"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             100000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100000 (390.62 KB)\n",
            "Trainable params: 100000 (390.62 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##'the glass of milk'= vector of sent 1\n",
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM-PHl_SVA1H",
        "outputId": "e473d81a-eda8-489e-ce54-bd616f7db8f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 6060,  908, 5247, 3547], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## each value of above array is represented by 10 features\n",
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj0bIMFYVXjH",
        "outputId": "918bdde9-5b31-429a-84c9-e0aaf4c4d9fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 141ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04983083,  0.02599504, -0.02120192, -0.04675944,  0.02521599,\n",
              "        -0.00745797,  0.01822691, -0.04080933, -0.04012754, -0.02952853],\n",
              "       [ 0.04983083,  0.02599504, -0.02120192, -0.04675944,  0.02521599,\n",
              "        -0.00745797,  0.01822691, -0.04080933, -0.04012754, -0.02952853],\n",
              "       [ 0.04983083,  0.02599504, -0.02120192, -0.04675944,  0.02521599,\n",
              "        -0.00745797,  0.01822691, -0.04080933, -0.04012754, -0.02952853],\n",
              "       [ 0.04983083,  0.02599504, -0.02120192, -0.04675944,  0.02521599,\n",
              "        -0.00745797,  0.01822691, -0.04080933, -0.04012754, -0.02952853],\n",
              "       [-0.00359077, -0.02939084,  0.03108886,  0.04770554, -0.04181021,\n",
              "        -0.04114711, -0.02472973,  0.00406317,  0.0401299 , -0.04588256],\n",
              "       [ 0.00115812,  0.01611612, -0.00490562, -0.01301813, -0.02049974,\n",
              "        -0.0385257 ,  0.0383878 ,  0.03551027, -0.04663881, -0.03728242],\n",
              "       [ 0.0320443 , -0.0186682 ,  0.00590358, -0.00282828, -0.02486416,\n",
              "         0.0060506 , -0.02765554,  0.01047004, -0.02827717, -0.01791488],\n",
              "       [-0.00914551, -0.01739172,  0.04351762,  0.04617849,  0.03085183,\n",
              "        -0.02190039,  0.03820712,  0.00463481, -0.00454111, -0.0088353 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 feature value of all sent\n",
        "print(model.predict(embedded_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtT8ArzGVXmD",
        "outputId": "51453dff-2ade-4d9a-eaf8-9c286681e153"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "[[[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [-0.00359077 -0.02939084  0.03108886  0.04770554 -0.04181021\n",
            "   -0.04114711 -0.02472973  0.00406317  0.0401299  -0.04588256]\n",
            "  [ 0.00115812  0.01611612 -0.00490562 -0.01301813 -0.02049974\n",
            "   -0.0385257   0.0383878   0.03551027 -0.04663881 -0.03728242]\n",
            "  [ 0.0320443  -0.0186682   0.00590358 -0.00282828 -0.02486416\n",
            "    0.0060506  -0.02765554  0.01047004 -0.02827717 -0.01791488]\n",
            "  [-0.00914551 -0.01739172  0.04351762  0.04617849  0.03085183\n",
            "   -0.02190039  0.03820712  0.00463481 -0.00454111 -0.0088353 ]]\n",
            "\n",
            " [[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [-0.00359077 -0.02939084  0.03108886  0.04770554 -0.04181021\n",
            "   -0.04114711 -0.02472973  0.00406317  0.0401299  -0.04588256]\n",
            "  [ 0.00115812  0.01611612 -0.00490562 -0.01301813 -0.02049974\n",
            "   -0.0385257   0.0383878   0.03551027 -0.04663881 -0.03728242]\n",
            "  [ 0.0320443  -0.0186682   0.00590358 -0.00282828 -0.02486416\n",
            "    0.0060506  -0.02765554  0.01047004 -0.02827717 -0.01791488]\n",
            "  [-0.04515814  0.0266172   0.04256649  0.04586858 -0.02700771\n",
            "   -0.03989291 -0.04730392  0.04953812 -0.02437377 -0.04006141]]\n",
            "\n",
            " [[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [-0.00359077 -0.02939084  0.03108886  0.04770554 -0.04181021\n",
            "   -0.04114711 -0.02472973  0.00406317  0.0401299  -0.04588256]\n",
            "  [ 0.0260443   0.01440624  0.02593858  0.03694259  0.00041502\n",
            "   -0.03009645 -0.01280401 -0.02307329 -0.03248782  0.0135665 ]\n",
            "  [ 0.0320443  -0.0186682   0.00590358 -0.00282828 -0.02486416\n",
            "    0.0060506  -0.02765554  0.01047004 -0.02827717 -0.01791488]\n",
            "  [-0.03814093  0.04726337  0.00969078  0.03540994 -0.02617596\n",
            "    0.02050172  0.04958339 -0.01937397 -0.00964192  0.03390718]]\n",
            "\n",
            " [[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04071233 -0.00681461 -0.04769066  0.02869317  0.0195979\n",
            "   -0.01271396 -0.02496341 -0.02264274  0.04346193 -0.02091687]\n",
            "  [ 0.00533292  0.00451527 -0.01596528  0.00775127 -0.01706483\n",
            "   -0.01837067 -0.01540643 -0.02944591  0.02305199 -0.04633768]\n",
            "  [ 0.01954006  0.02613923  0.01139691  0.02788936  0.00356113\n",
            "   -0.03114057  0.01372625 -0.00694823  0.0034701  -0.0477054 ]\n",
            "  [ 0.04826069 -0.04889913  0.0323134  -0.04757702 -0.01243507\n",
            "   -0.01115786  0.03125538  0.00787014 -0.0097082   0.04073038]\n",
            "  [-0.03754721 -0.02335302 -0.03733031 -0.02625635 -0.04258102\n",
            "   -0.04629722 -0.04075675 -0.02276225  0.03107584  0.01361512]]\n",
            "\n",
            " [[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04071233 -0.00681461 -0.04769066  0.02869317  0.0195979\n",
            "   -0.01271396 -0.02496341 -0.02264274  0.04346193 -0.02091687]\n",
            "  [ 0.00533292  0.00451527 -0.01596528  0.00775127 -0.01706483\n",
            "   -0.01837067 -0.01540643 -0.02944591  0.02305199 -0.04633768]\n",
            "  [ 0.01954006  0.02613923  0.01139691  0.02788936  0.00356113\n",
            "   -0.03114057  0.01372625 -0.00694823  0.0034701  -0.0477054 ]\n",
            "  [ 0.04826069 -0.04889913  0.0323134  -0.04757702 -0.01243507\n",
            "   -0.01115786  0.03125538  0.00787014 -0.0097082   0.04073038]\n",
            "  [ 0.02088633 -0.01323677 -0.01852629  0.02317697 -0.03039349\n",
            "   -0.0056171   0.01801256 -0.02914979  0.0174222   0.03794379]]\n",
            "\n",
            " [[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04521822  0.03960574  0.00015569 -0.02043133 -0.0105776\n",
            "   -0.03581971 -0.0185592  -0.04208731 -0.00449555 -0.02828786]\n",
            "  [-0.00359077 -0.02939084  0.03108886  0.04770554 -0.04181021\n",
            "   -0.04114711 -0.02472973  0.00406317  0.0401299  -0.04588256]\n",
            "  [ 0.04804157  0.0134071  -0.04361701 -0.01011007 -0.03317492\n",
            "   -0.04926338  0.04454452 -0.04354577 -0.00799783  0.02434142]\n",
            "  [ 0.0320443  -0.0186682   0.00590358 -0.00282828 -0.02486416\n",
            "    0.0060506  -0.02765554  0.01047004 -0.02827717 -0.01791488]\n",
            "  [ 0.04263229 -0.00881391 -0.03358539 -0.03712445  0.04538849\n",
            "   -0.02036799  0.01332618  0.00908986 -0.01132347  0.01181478]]\n",
            "\n",
            " [[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599\n",
            "   -0.00745797  0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            "  [ 0.02313304 -0.00572749  0.03602976  0.01844038 -0.02386816\n",
            "   -0.0340439  -0.00468627 -0.03402556 -0.03027401  0.03261441]\n",
            "  [-0.02443081 -0.0471114  -0.00565083  0.03099972 -0.02205916\n",
            "   -0.03987189  0.02358771  0.03850127  0.03324832 -0.03299161]\n",
            "  [-0.02112201  0.00260061  0.04746274 -0.02254404  0.01985596\n",
            "   -0.03560507 -0.00588809 -0.02503928  0.03242839  0.04184127]\n",
            "  [ 0.04826069 -0.04889913  0.0323134  -0.04757702 -0.01243507\n",
            "   -0.01115786  0.03125538  0.00787014 -0.0097082   0.04073038]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR-_oJ77VXo4",
        "outputId": "82c95446-002e-4e3d-ade5-d439847a55b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 6060,  908, 5247, 3547], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FILL3AgVXrD",
        "outputId": "d0eac06c-8bbe-4cb5-dd2d-84a80f98e3e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "[[ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599 -0.00745797\n",
            "   0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            " [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599 -0.00745797\n",
            "   0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            " [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599 -0.00745797\n",
            "   0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            " [ 0.04983083  0.02599504 -0.02120192 -0.04675944  0.02521599 -0.00745797\n",
            "   0.01822691 -0.04080933 -0.04012754 -0.02952853]\n",
            " [-0.00359077 -0.02939084  0.03108886  0.04770554 -0.04181021 -0.04114711\n",
            "  -0.02472973  0.00406317  0.0401299  -0.04588256]\n",
            " [ 0.00115812  0.01611612 -0.00490562 -0.01301813 -0.02049974 -0.0385257\n",
            "   0.0383878   0.03551027 -0.04663881 -0.03728242]\n",
            " [ 0.0320443  -0.0186682   0.00590358 -0.00282828 -0.02486416  0.0060506\n",
            "  -0.02765554  0.01047004 -0.02827717 -0.01791488]\n",
            " [-0.00914551 -0.01739172  0.04351762  0.04617849  0.03085183 -0.02190039\n",
            "   0.03820712  0.00463481 -0.00454111 -0.0088353 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jir_uVk5VXuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0fkaLCvUVXxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ssFsnrkVA3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-d-0M7UVA55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcY41CacVA8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2l1mTCA8VA_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUHkCffOVBB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_HGG78aVBEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fOyqXMXQVBIG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}